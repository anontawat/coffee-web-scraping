{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e513698",
   "metadata": {},
   "source": [
    "# Arabica Coffee Scores Web Scraping\n",
    "\n",
    "This project is about applying knowledge from web scraping and because I would like to update my case study project to make the data present. The case study project uses the data from the year **2017** from [Kaggle](https://www.kaggle.com/volpatto/coffee-quality-database-from-cqi). Below are the steps taken to scrap the data.\n",
    "\n",
    "Before you can follow the steps below, you will need to install Selenium and WebDriver to your local PC.\n",
    "- Selenium: [How to install](https://selenium-python.readthedocs.io/)\n",
    "- ChromeDriver: [Download ChromeDriver](https://chromedriver.chromium.org/downloads), you must download the ChromeDriver the same version as your browser. You can use different browsers and follow along. \n",
    "\n",
    "## 1. Import The Modules\n",
    "I use Selenium package because the BeautifulSoup cannot handle dynamic websites scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3971fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae9d0d",
   "metadata": {},
   "source": [
    "## 2. Set Up The Working Directory\n",
    "\n",
    "This is for changing the working directory to the same place I downloaded the ChromeDriver to make it simulate and store information in the same place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9078bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set directory to the same place as ChromeWebDriver\n",
    "path = 'C:/Users/medse/Downloads/Installations/' \n",
    "os.chdir(path) #Chage working directory to the desired path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d777c",
   "metadata": {},
   "source": [
    "## 3. Run the WebDriver to CQI website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "446c3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open WebdDriver \n",
    "s = Service(path + \"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service = s)\n",
    "driver.get('https://database.coffeeinstitute.org/coffees/arabica') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53db2f4",
   "metadata": {},
   "source": [
    "## 4. Observe The Site Structure\n",
    "\n",
    "If you visit the site, you can see that there are 3 pages and each page contains links where you can click on in order to go to the data page for each coffee. Therefore, because of the small number of pages, I can just grasp the link from each page and connect them together by making the driver click to the next page after getting all the links.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f7a2da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import another module for working with XPATH\n",
    "from selenium.webdriver.common.by import By\n",
    "#Get location of links from 3 pages\n",
    "link_1 = driver.find_elements(By.XPATH, \"//a[contains(text(), '#')]\")\n",
    "page_2 = driver.find_element(By.XPATH, \"//*[@id='DataTables_Table_0_paginate']/span/a[2]\").click\n",
    "link_2 = driver.find_elements(By.XPATH, \"//a[contains(text(), '#')]\")\n",
    "page_3 = driver.find_element(By.XPATH, \"//*[@id='DataTables_Table_0_paginate']/span/a[3]\").click\n",
    "link_3 = driver.find_elements(By.XPATH, \"//a[contains(text(), '#')]\")\n",
    "links = link_1 + link_2 + link_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b6ba4e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total links is 150\n"
     ]
    }
   ],
   "source": [
    "#Get links text by using get_attribute\n",
    "Links = [link.get_attribute('href') for link in links]\n",
    "print(\"The total links is\", len(Links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f3224",
   "metadata": {},
   "source": [
    "## 5. Export The Links to a DataFrame For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a1329c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe and export to excel to test\n",
    "arabica_coffee_2021 = pd.DataFrame({\"coffee_link\": Links})\n",
    "arabica_coffee_2021.to_excel('C:\\\\Users\\\\medse\\\\OneDrive\\\\Desktop\\\\Google Data Analytics Cert\\\\Sample_Data\\\\case_study_data\\\\arabica_coffee_2021_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3f8e058b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://database.coffeeinstitute.org/coffee/27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://database.coffeeinstitute.org/coffee/88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://database.coffeeinstitute.org/coffee/11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://database.coffeeinstitute.org/coffee/26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://database.coffeeinstitute.org/coffee/97...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         coffee_link\n",
       "0  https://database.coffeeinstitute.org/coffee/27...\n",
       "1  https://database.coffeeinstitute.org/coffee/88...\n",
       "2  https://database.coffeeinstitute.org/coffee/11...\n",
       "3  https://database.coffeeinstitute.org/coffee/26...\n",
       "4  https://database.coffeeinstitute.org/coffee/97..."
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabica_coffee_2021.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d40bfd",
   "metadata": {},
   "source": [
    "## 6. Test The First Link \n",
    "\n",
    "After getting all the links to the data for each coffee, I will go to the first link to pull out the data I need. I will need the following 25 columns:\n",
    "\n",
    "1. Country_Of_Origin\n",
    "2. Farm_Name\n",
    "3. Lot_Number\n",
    "4. Mill\n",
    "5. Grading_Date\n",
    "6. Owner\n",
    "7. Company\n",
    "8. Altitude\n",
    "9. Variety\n",
    "10. Region\n",
    "11. Producer\n",
    "12. Process\n",
    "13. Aroma\n",
    "14. Flavour\n",
    "15. Aftertaste\n",
    "16. Acidity\n",
    "17. Body\n",
    "18. Balance\n",
    "19. Uniformity\n",
    "20. Clean_Cup\n",
    "21. Sweetness\n",
    "22. Overall\n",
    "23. Defects\n",
    "24. Total_Cup_Points\n",
    "25. Expiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "032be0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the first link\n",
    "driver.get(Links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a5fcfa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taiwan\n",
      "QingShanPingKaFeiNongChang青山坪咖啡農場\n",
      "202104\n",
      "yes\n",
      "December 13th, 2021\n",
      "Qingshanping\n",
      "QingShanPingKaFeiNongChang青山坪咖啡農場\n",
      "800\n",
      "Gesha\n",
      "Caoling, Gukeng Township, Yunlin County\n",
      "王清連\n",
      "Natural / Dry\n",
      "8.25\n",
      "8.25\n",
      "8.08\n",
      "8.33\n",
      "8.00\n",
      "8.17\n",
      "10.00\n",
      "10.00\n",
      "10.00\n",
      "8.17\n",
      "0.00\n",
      "87.25\n",
      "December 13th, 2022\n",
      "['https://database.coffeeinstitute.org/coffee/272474', 'https://database.coffeeinstitute.org/coffee/885383', 'https://database.coffeeinstitute.org/coffee/119483', 'https://database.coffeeinstitute.org/coffee/266250', 'https://database.coffeeinstitute.org/coffee/978171']\n"
     ]
    }
   ],
   "source": [
    "#Get Country of Origin\n",
    "country_of_origin = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[1]/td[1]\").text\n",
    "\n",
    "#Get Farm Name\n",
    "farm_name = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[2]/td[1]\").text\n",
    "\n",
    "#Get Lot Number\n",
    "lot_number = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[3]/td[1]\").text\n",
    "\n",
    "#Get Mill\n",
    "mill = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[4]/td[1]\").text\n",
    "\n",
    "#Get Grading Date\n",
    "grading_date = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[5]/td[2]\").text\n",
    "\n",
    "#Get Owner\n",
    "owner = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[6]/td[2]\").text\n",
    "\n",
    "#Get Company\n",
    "company = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[6]/td[1]\").text\n",
    "\n",
    "#Get Altitude\n",
    "altitude = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[7]/td[1]\").text\n",
    "\n",
    "#Get Variety\n",
    "variety = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[7]/td[2]\").text\n",
    "\n",
    "#Get Region\n",
    "region = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[8]/td[1]\").text\n",
    "\n",
    "#Get Producer\n",
    "producer = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[9]/td[1]\").text\n",
    "\n",
    "#Get Processing method\n",
    "process = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[9]/td[2]\").text\n",
    "\n",
    "#Get Aroma\n",
    "aroma = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[1]/td[1]\").text\n",
    "\n",
    "#Get Flavour\n",
    "flavour = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[2]/td[1]\").text\n",
    "\n",
    "#Get Aftertaste\n",
    "aftertaste = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[3]/td[1]\").text\n",
    "\n",
    "#Get Acidity\n",
    "acidity = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[4]/td[1]\").text\n",
    "\n",
    "#Get Body\n",
    "body = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[5]/td[1]\").text\n",
    "\n",
    "#Get Balance\n",
    "balance = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[6]/td[1]\").text\n",
    "\n",
    "#Get Uniformity\n",
    "uniformity = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[1]/td[2]\").text\n",
    "\n",
    "#Get Clean Cup\n",
    "clean_cup = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[2]/td[2]\").text\n",
    "\n",
    "#Get Sweetness\n",
    "sweetness = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[3]/td[2]\").text\n",
    "\n",
    "#Get Overall\n",
    "overall = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[4]/td[2]\").text\n",
    "\n",
    "#Get Defects\n",
    "defects = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[5]/td[2]\").text\n",
    "\n",
    "#Get Total Cup Points\n",
    "total_cup_points = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[6]/td[2]\").text\n",
    "\n",
    "#Get Expiration\n",
    "expiration = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[4]/tbody/tr[1]/td\").text\n",
    "\n",
    "print(country_of_origin)\n",
    "print(farm_name)\n",
    "print(lot_number)\n",
    "print(mill)\n",
    "print(grading_date)\n",
    "print(owner)\n",
    "print(company)\n",
    "print(altitude)\n",
    "print(variety)\n",
    "print(region)\n",
    "print(producer)\n",
    "print(process)\n",
    "print(aroma)\n",
    "print(flavour)\n",
    "print(aftertaste)\n",
    "print(acidity)\n",
    "print(body)\n",
    "print(balance)\n",
    "print(uniformity)\n",
    "print(clean_cup)\n",
    "print(sweetness)\n",
    "print(overall)\n",
    "print(defects)\n",
    "print(total_cup_points)\n",
    "print(expiration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c8bd6",
   "metadata": {},
   "source": [
    "## 7. Go Through Every Link to Get All the Coffee Data\n",
    "\n",
    "Here is the main part of the code. Please notice that I need to import more modules because I faced the problem with page loading. When the page wasn't fully loaded, the Selenium couldn't find the specific element from the XPATH, and that's why I need to set up the waiting time for at least the first part (**country of origin**) to be loaded in order to locate the correct element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3ef524cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n",
      "Page loaded\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Set lists to keep data in each link\n",
    "Country_Of_Origin = []\n",
    "Farm_Name = []\n",
    "Lot_Number = []\n",
    "Mill = []\n",
    "Grading_Date = []\n",
    "Owner = []\n",
    "Company = []\n",
    "Altitude = []\n",
    "Variety = []\n",
    "Region = []\n",
    "Producer = []\n",
    "Process = []\n",
    "Aroma = []\n",
    "Flavour = []\n",
    "Aftertaste = []\n",
    "Acidity = []\n",
    "Body = []\n",
    "Balance = []\n",
    "Uniformity = []\n",
    "Clean_Cup = []\n",
    "Sweetness = []\n",
    "Overall = []\n",
    "Defects = []\n",
    "Total_Cup_Points = []\n",
    "Expiration = []\n",
    "\n",
    "#Loop the links\n",
    "for link in range(0, len(Links)):\n",
    "    driver.get(Links[link])\n",
    "    #Set up the waiting time to wait until the first data I need to pull is fully loaded\n",
    "    timeout = 5\n",
    "    try:\n",
    "        element_present = EC.presence_of_element_located((By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[1]/td[1]\"))\n",
    "        WebDriverWait(driver, timeout).until(element_present)\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "    finally:\n",
    "        print(\"Page loaded\")\n",
    "    \n",
    "    #Get Country of Origin\n",
    "    country_of_origin = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[1]/td[1]\").text\n",
    "\n",
    "    #Get Farm Name\n",
    "    farm_name = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[2]/td[1]\").text\n",
    "\n",
    "    #Get Lot Number\n",
    "    lot_number = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[3]/td[1]\").text\n",
    "\n",
    "    #Get Mill\n",
    "    mill = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[4]/td[1]\").text\n",
    "\n",
    "    #Get Grading Date\n",
    "    grading_date = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[5]/td[2]\").text\n",
    "\n",
    "    #Get Owner\n",
    "    owner = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[6]/td[2]\").text\n",
    "\n",
    "    #Get Company\n",
    "    company = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[6]/td[1]\").text\n",
    "\n",
    "    #Get Altitude\n",
    "    altitude = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[7]/td[1]\").text\n",
    "\n",
    "    #Get Variety\n",
    "    variety = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[7]/td[2]\").text\n",
    "\n",
    "    #Get Region\n",
    "    region = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[8]/td[1]\").text\n",
    "\n",
    "    #Get Producer\n",
    "    producer = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[9]/td[1]\").text\n",
    "\n",
    "    #Get Processing method\n",
    "    process = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[1]/tbody/tr[9]/td[2]\").text\n",
    "\n",
    "    #Get Aroma\n",
    "    aroma = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[1]/td[1]\").text\n",
    "\n",
    "    #Get Flavour\n",
    "    flavour = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[2]/td[1]\").text\n",
    "\n",
    "    #Get Aftertaste\n",
    "    aftertaste = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[3]/td[1]\").text\n",
    "\n",
    "    #Get Acidity\n",
    "    acidity = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[4]/td[1]\").text\n",
    "\n",
    "    #Get Body\n",
    "    body = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[5]/td[1]\").text\n",
    "\n",
    "    #Get Balance\n",
    "    balance = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[6]/td[1]\").text\n",
    "\n",
    "    #Get Uniformity\n",
    "    uniformity = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[1]/td[2]\").text\n",
    "\n",
    "    #Get Clean Cup\n",
    "    clean_cup = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[2]/td[2]\").text\n",
    "\n",
    "    #Get Sweetness\n",
    "    sweetness = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[3]/td[2]\").text\n",
    "\n",
    "    #Get Overall\n",
    "    overall = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[4]/td[2]\").text\n",
    "\n",
    "    #Get Defects\n",
    "    defects = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[5]/td[2]\").text\n",
    "\n",
    "    #Get Total Cup Points\n",
    "    total_cup_points = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[2]/tbody/tr[6]/td[2]\").text\n",
    "\n",
    "    #Get Expiration\n",
    "    expiration = driver.find_element(By.XPATH, \"/html/body/content/div/div[2]/div[2]/div/table[4]/tbody/tr[1]/td\").text\n",
    "    \n",
    "    #Append data in each list\n",
    "    Country_Of_Origin.append(country_of_origin)\n",
    "    Farm_Name.append(farm_name)\n",
    "    Lot_Number.append(lot_number)\n",
    "    Mill.append(mill)\n",
    "    Grading_Date.append(grading_date)\n",
    "    Owner.append(owner)\n",
    "    Company.append(company)\n",
    "    Altitude.append(altitude)\n",
    "    Variety.append(variety)\n",
    "    Region.append(region)\n",
    "    Producer.append(producer)\n",
    "    Process.append(process)\n",
    "    Aroma.append(aroma)\n",
    "    Flavour.append(flavour)\n",
    "    Aftertaste.append(aftertaste)\n",
    "    Acidity.append(acidity)\n",
    "    Body.append(body)\n",
    "    Balance.append(balance)\n",
    "    Uniformity.append(uniformity)\n",
    "    Clean_Cup.append(clean_cup)\n",
    "    Sweetness.append(sweetness)\n",
    "    Overall.append(overall)\n",
    "    Defects.append(defects)\n",
    "    Total_Cup_Points.append(total_cup_points)\n",
    "    Expiration.append(expiration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd2a8a",
   "metadata": {},
   "source": [
    "## 8. Create A New DataFrame And Export\n",
    "\n",
    "Once I've got all the data kept in the lists above, I will create a new dataframe from those list. After that, I will concat the this dataframe to the one I created earlier and export it to the excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ffee178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new DataFrame from the links above\n",
    "arabica_coffee_2021_2 = pd.DataFrame({\n",
    "    'country_of_origin': Country_Of_Origin,\n",
    "    'farm_name': Farm_Name,\n",
    "    'lot_number': Lot_Number,\n",
    "    'mill': Mill,\n",
    "    'grading_date': Grading_Date,\n",
    "    'owner': Owner,\n",
    "    'company': Company,\n",
    "    'altitude': Altitude,\n",
    "    'variety': Variety,\n",
    "    'region': Region,\n",
    "    'producer': Producer,\n",
    "    'process': Process,\n",
    "    'aroma': Aroma,\n",
    "    'flavour': Flavour,\n",
    "    'aftertaste': Aftertaste,\n",
    "    'acidity': Acidity,\n",
    "    'body': Body,\n",
    "    'balance': Balance,\n",
    "    'uniformity': Uniformity,\n",
    "    'clean_cup': Clean_Cup, \n",
    "    'sweetness': Sweetness,\n",
    "    'overall': Overall,\n",
    "    'defects': Defects,\n",
    "    'total_cup_points': Total_Cup_Points,\n",
    "    'expiration': Expiration\n",
    "})\n",
    "\n",
    "#Concatenate 2 DataFrame\n",
    "arabica_coffee_2021 = pd.concat([arabica_coffee_2021, arabica_coffee_2021_2], axis=1)\n",
    "\n",
    "#Export to an excel file\n",
    "arabica_coffee_2021.to_excel('C:\\\\Users\\\\medse\\\\OneDrive\\\\Desktop\\\\Google Data Analytics Cert\\\\Sample_Data\\\\case_study_data\\\\arabica_coffee_2021.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9dff70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
